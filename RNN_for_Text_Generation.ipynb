{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN for Text Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy3Onu_xT4bA"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNCN5EhmyJsm",
        "outputId": "082734f7-19d4-4839-afcf-b550d36909c5"
      },
      "source": [
        "with open('sherlock_homes.txt', 'r') as file:\n",
        "    text = file.read().lower()\n",
        "print('text length', len(text))\n",
        "\n",
        "chars = sorted(list(set(text))) # getting all unique chars\n",
        "print('total chars: ', len(chars))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text length 581864\n",
            "total chars:  63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6VCqEHGyKia"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHooROauyQPm",
        "outputId": "66f11c62-1ff5-4e7a-ea1a-069b93d6dc11"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM0C7GvpyQR5"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "        \n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTFWuXgtyQTj"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwCEtojozYyH"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcntMF9yyau2"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)\n",
        "\n",
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTY7KDYwyazN",
        "outputId": "0095ce8e-36b3-4b86-c2f7-8670ca24f5d2"
      },
      "source": [
        "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1516/1516 [==============================] - 188s 113ms/step - loss: 2.2316\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"r secret lies in london. it is there tha\"\n",
            "r secret lies in london. it is there that the took of the look of the look with the tark and to the to the stand of the tate. it was a seet to the door of the litely to the dought to the door of the trought to the trong to the look to the look of the door of the took and lare at the dought to the loot of the tood and the to the door of the litely to the tood and the dout man to the tany of the to the father and the to the lite the tood \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"r secret lies in london. it is there tha\"\n",
            "r secret lies in london. it is there that had and in the dast of the sining sout, and is and to the formed the dirccond and of the plair, and had the dear heard to\n",
            "the tread and and done of my last the tour man compunion to the time of the rest at the fars of the father with the look was a grided to the read of my litely to sten the hout was all convent, then, i mad hew ever all dirately the eater and at were uson candser to at might to\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"r secret lies in london. it is there tha\"\n",
            "r secret lies in london. it is there that it was aloubty one\n",
            "but his enculns, of that i walls keellir hand to their hars gout over the wort. it?\" i cas\n",
            "lately. i shinn cance with the course sees \"it eathed to fare lare, hisper to went, my breads of the feature. the dougptar for\n",
            "'not eay\n",
            "day mary.\n",
            "\n",
            "hat becons, your aes had plays out her tet at liod from very perlop at\n",
            "be him. and thesing\n",
            "loving to pleppen ufink, and pair the tonxpays,\n",
            " w\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"r secret lies in london. it is there tha\"\n",
            "r secret lies in london. it is there that\n",
            "sucret of as srivur tage bateon. mr.\n",
            "hows wrollow slip peete was cheep, and divark it, froated, one of the takled, and soembees, -has alwadion of gurmour teels from chag\" of shites.\n",
            "\n",
            "\"\n",
            "the fresemberar.\n",
            "\"well meselfveraul woft, et miss eacled to gon, anyduintion misifrite-plally of done know diughold to the tisleppyres,' sa date\n",
            "had\n",
            "quift, and tugnittery-s was elacc it with a\n",
            "sawely his me. the t\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.94234, saving model to weights.hdf5\n",
            "Epoch 2/5\n",
            "1516/1516 [==============================] - 173s 114ms/step - loss: 1.6296\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"e of our lives. i\n",
            "could see a change in \"\n",
            "e of our lives. i\n",
            "could see a change in the some to me. i shall the door and the trought the more that i have the trong the some and the toom that the proppention of the room to me. he was a states to me to me. i have the trought to my the more that i should not a some to my the room that the some to the trourd and the room which i have the trome and so the room that i have the trong the lottle of the troome and the door and the room to\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"e of our lives. i\n",
            "could see a change in \"\n",
            "e of our lives. i\n",
            "could see a change in the more me.\n",
            "\n",
            "\"'this it was not my weal a door and some of the room which have loing the town, and he problumed to the trome that the seccessition which i have the tope and brought the promition. i am sure that and the face of the more the dress which has been out of the tone and the more to the words to her the toll have the door to the sontant, and he\n",
            "do night it was street, and the room in the \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"e of our lives. i\n",
            "could see a change in \"\n",
            "e of our lives. i\n",
            "could see a change in a\n",
            "remay an atates of  facting at nove, and three, theurods were soment bode which yat some told hommitance, bround your you\n",
            "forwed, then, i feot tray reeverly the\n",
            "sovergraged in us it somey perpowed the rooms to al about by the hol other.\"\n",
            "\n",
            "\"andiyes, i is no toureing that i pave for my hing?\"\n",
            "\n",
            "lot upon?\" i walk,\n",
            "then her disemsas, and i sunded it of a lodge\n",
            "af sitshess,\n",
            "the room.\n",
            "\n",
            "ouf a live?\"\n",
            "\n",
            "\"c\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"e of our lives. i\n",
            "could see a change in \"\n",
            "e of our lives. i\n",
            "could see a change in lork, but she\n",
            "went his ntwing guint, over me.\"\n",
            "\n",
            "\"it you to wo ucandlufuard, and\n",
            "it was o-hably-prodn storge. lot goch you.\"\n",
            "\n",
            "\"goo you sooe.\n",
            " \"with bleared tebeven old within a littlurs, i have you were as two, jurg ppone, with arle\n",
            "sponving,\"\n",
            "said, thing treatumine, xpeletow?\"\n",
            "\n",
            "\"my guines a\n",
            "woindand-it\n",
            " insomecedm that my ecpupen. i oil\n",
            "by them. prodoequr for\n",
            "you heard withing rnoush fromably afte\n",
            "\n",
            "Epoch 00002: loss improved from 1.94234 to 1.61174, saving model to weights.hdf5\n",
            "Epoch 3/5\n",
            "1516/1516 [==============================] - 173s 114ms/step - loss: 1.5149\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"in to think, watson,\" said holmes, \"that\"\n",
            "in to think, watson,\" said holmes, \"that is a considerable street, and the stand of the stand. the states, and the stronge and to the street, and the strange trange of the singular was an advance of the street, and the considerable street, and i had been stronge and the stronge and some stare that he was a stand of the stand and the man who had been stronge the man who had all the stronge of the street, and the some strange the stairs o\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"in to think, watson,\" said holmes, \"that\"\n",
            "in to think, watson,\" said holmes, \"that you are some note, and i result and to the trun's street, my fatient, and the surgence. when she wondered up in the contule of the stand. when i are succeed in the some at the deep who had even do you man so than it would not have be see the man who are all close the spene of each to the repreded in the considered up in his chattered a consultic reading the sleever on the projected, so the come a\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"in to think, watson,\" said holmes, \"that\"\n",
            "in to think, watson,\" said holmes, \"that iade ho centulan outsed intt which had all, some yournd-coronet--pelems gantly a dring-'bink it. poot could only be unferened to 'he hold out in the ray thore, at your holmed fature confotioubles with a clary seoul less shaghan. if you dusinal, servadian.\"\n",
            "\n",
            "\"it is\n",
            "resirul, sadit he was the crining--wh-he can up sloth rompw.\"\n",
            "\n",
            "suldo, we have the\n",
            "men conlearpalien, and mri ew mr. to with\n",
            "to be a fa\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"in to think, watson,\" said holmes, \"that\"\n",
            "in to think, watson,\" said holmes, \"that !ea preciened sucdedwal was swrived\n",
            "whispent?' '\"\n",
            "\n",
            "'what i see them to un that rome why gry s. inflely,   do. commenat it,onw,'s  crivicalled, a turgeted one. 'that the colven. on the corticek-t'op\n",
            "all thoughhe famalosuodliy.' preseateded, tofbified as i tlanak folain vomat\n",
            "pnewly.'\n",
            "\n",
            "\"'yes. so of this\n",
            "came outight, meliod lest to sugved. sin to capy's from his couptrant.\"\n",
            "\n",
            "\"ever broy see my goodd\n",
            "\n",
            "Epoch 00003: loss improved from 1.61174 to 1.51696, saving model to weights.hdf5\n",
            "Epoch 4/5\n",
            "1516/1516 [==============================] - 173s 114ms/step - loss: 1.4605\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"one. she had\n",
            "hardly listened to his inst\"\n",
            "one. she had\n",
            "hardly listened to his instation of the confirmositions of the man who is a signity of a colour and to her some street of a street of the door and to him to her and passed to her of the disconstation of the house of the at the face of the more and to the beater to him at the man of the past of the other stood in the door of the door and to him to her confision of the man who has been as a fate of the farthar and to the man \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"one. she had\n",
            "hardly listened to his inst\"\n",
            "one. she had\n",
            "hardly listened to his instation of a little of the little and had to have a little and a kee up which as a little as to us of some of the colour of my trome at the trees whe had our of my fewe and looked in the took of the instation of the first and perhaps i had a garcer and to the reather proppstain of the matter before which i had distived in the beated to her accistions of the morning of coroner of my confire of the co\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"one. she had\n",
            "hardly listened to his inst\"\n",
            "one. she had\n",
            "hardly listened to his instations to find a caver within af my positticic and\n",
            "or coling about it impupaie in the fight and a cigure and flamue no head weve what i am\n",
            "aory the ofgessoun. it is cot and of my office of\n",
            "the\n",
            "erglarest who had he sucretts disctated mean hand and out of rang had, and ploy had for arsonic was take in. you sprang man who criece\n",
            "prable colour who could night papers my from what was absurd good and\n",
            "wh\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"one. she had\n",
            "hardly listened to his inst\"\n",
            "one. she had\n",
            "hardly listened to his instectation after the beater whet wonkny kee uh of tabering our so. i\n",
            "have \n",
            "esunt. warking you to\n",
            "ut, mist stations. but he pro'psy of that mogend to gear, i ome-merenos.\"\n",
            "\n",
            "\"i enduling times unlipshity. it\n",
            "was a tisthess that my windigible fellow, at the oth,\n",
            "'vil?' in alamor, mntogia queltical in.n when my gee of no any tright twiss\n",
            "pawe he explanation,\n",
            "ppalusly to visit arnly his dteewqup. my toopi\n",
            "\n",
            "Epoch 00004: loss improved from 1.51696 to 1.46644, saving model to weights.hdf5\n",
            "Epoch 5/5\n",
            "1516/1516 [==============================] - 172s 114ms/step - loss: 1.4228\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" street, \"life is infinitely\n",
            "stranger th\"\n",
            " street, \"life is infinitely\n",
            "stranger the project gutenberg-tm country-face and was the besterness in the straight stated the states, and the straight and the standies which i had been been was and that the words in the country, and the standion, and the believe that i was a stared with the straight and the words of the states of the states, and the first of the country. the states of the left to the official the work and the stared the\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" street, \"life is infinitely\n",
            "stranger th\"\n",
            " street, \"life is infinitely\n",
            "stranger that i was a ban and a black in the outsed the locking one states which he descreated at the words and the secret, and i was at the concluing of the other stoon project gutenberg far when i had only the way to the cold words that i was as when i can the hight with his lady and in the states, retaining to me that i had hearts to come when he could not stop the backenred for sight that you have stepse\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" street, \"life is infinitely\n",
            "stranger th\"\n",
            " street, \"life is infinitely\n",
            "stranger that a carromaiting stood. \"what were.\"\n",
            "\n",
            "\"oh, as to much seeing fane of mucely wr.eh between, and for the regettly. and i would certain in the words of one hoperend had been\n",
            "had every\n",
            "mearches which the insker beer to le every distared the pubding not your street, and\n",
            "that\n",
            "round\n",
            "finad the\n",
            "wroding a large peetlad you under the licenseantion, pulricg\n",
            "you carrome to her busily of the anderents for\n",
            "week\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" street, \"life is infinitely\n",
            "stranger th\"\n",
            " street, \"life is infinitely\n",
            "stranger the year, but in my house, have purstion. before yet, p!r\"ill, whi he better woganal alnir he. must go\n",
            "mergive wayd mystairat,\n",
            "over bours a morning of\n",
            "ray. he blough as i underitaed, and that\n",
            "was,\n",
            "dopy, you,wank -passilisffor thophcondable probeokerxghe in hande 'bar dake had infolpyth-head upexpen\n",
            "fold to\n",
            "do so to have public ald some vieretuence finishy.\" i aysever up, mavilatoon. comes, earso tha\n",
            "\n",
            "Epoch 00005: loss improved from 1.46644 to 1.43453, saving model to weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc0bb9d6b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25zDy_iJU_53"
      },
      "source": [
        "def generate_text(length, diversity):\n",
        "    # Get random starting text\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "    return generated"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4PSbpPwyjqc",
        "outputId": "263f61f3-090d-490c-9ea5-d7f1722f7809"
      },
      "source": [
        "print(generate_text(500, 0.2))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f\n",
            "despair. \"if his motives were innocent and was a stare and was and the stare and the country--the door which was a country. the breasor which was a stare and the country. the lady of the bent and the bell-rubberred the states of the strangered of the way to the country of the states, with the street, and the words in the bell-roped the states of the street, and the words and the states of the street, and the standion of the besterned to the strangered in the states, which i have been was to the great that the work and the face and t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDvWrxeRzEYP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}